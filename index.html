<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
  <meta name="keywords" content="Scene Co-pilot, BlenderGPT, 3d assests dataset">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Scene Co-pilot: Procedural Text to Video Generation with Human in the Loop</title>
  <link rel="icon" type="./static/images/fav.png" href="/images/favicon.ico">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/video_text.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>

</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Scene Co-pilot: Procedural Text to Video Generation with Human in the Loop</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Zhaofang Qian<sup>1</sup>,
			  </span>
            <span class="author-block">
              Abolfazl Sharifi<sup>2</sup>,
			  </span>
            <span class="author-block">
              Tucker Carroll<sup>1</sup>,
            </span>
            <span class="author-block">
              Ser-Nam Lim<sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Central Florida,</span>
            <span class="author-block"><sup>2</sup>University of Kashan</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. 
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span-->
              <!-- Dataset Link. 
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span> -->
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="video-margin">
	 
	    <video class="item" poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/a blooming cherry blossom tree under a blue sky with white clouds.mp4"
                    type="video/mp4">		
        </video>
			<div class="caption">
			 <center>Blooming Cherry: The Blooming cherry blossom tree</center>
			</div>
		</div>

        <div class="video-margin">
	 
	    <video class="item" poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/a monument under the blue sky.mp4"
                    type="video/mp4">		
        </video>
			<div class="caption">
			 <center>Monument: A monument under the blue sky</center>
			</div>
		</div>
		
		
		        <div class="video-margin">
	 
	    <video class="item" poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/clouds formation in the sky at sunset.mp4"
                    type="video/mp4">		
        </video>
			<div class="caption">
			 <center>Clouds: The formation of clouds at sunset</center>
			</div>
		</div>
		
		        <div class="video-margin">
	 
	    <video class="item" poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/F10_underwater.mp4"
                    type="video/mp4">		
        </video>
			<div class="caption">
			 <center>Underwater: The underwater sea world</center>
			</div>
		</div>
		
		        <div class="video-margin">
	 
	    <video class="item" poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/Fig10_desert_snake.mp4"
                    type="video/mp4">		
        </video>
			<div class="caption">
			 <center>Desert: The snake in the desert</center>
			</div>
		</div>
		
		        <div class="video-margin">
	 
	    <video class="item" poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/Fig10a_arctic.mp4"
                    type="video/mp4">		
        </video>
			<div class="caption">
			 <center>Arctic: The movement of sea ice</center>
			</div>
		</div>
		
		        <div class="video-margin">
	 
	    <video class="item" poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/Fig10c_nature_stream.mp4"
                    type="video/mp4">		
        </video>
			<div class="caption">
			 <center>Nature: A Wide shot of a beautiful nature</center>
			</div>
		</div>
		
		        <div class="video-margin">
	 
	    <video class="item" poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/Fig10d_sunset.mp4"
                    type="video/mp4">		
        </video>
			<div class="caption">
			 <center>Sunset: The sunset in the desert</center>
			</div>
		</div>
				 <div class="video-margin">
	 
	    <video class="item" poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/view of a jack o lantern with pumpkins in a smoky garden.mp4"
                    type="video/mp4">		
        </video>
			<div class="caption">
			 <center>Pumkins: Jacks o lantern with pumpkins in the garden</center>
			</div>
		</div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
			<p>
          Video generation has achieved impressive quality, but it still suffers from artifacts such as temporal inconsistency and violation of physical laws. Leveraging 3D scenes can fundamentally resolve these issues by providing precise control over scene entities. To facilitate the easy generation of diverse photorealistic scenes, we propose  Scene Copilo, a framework combining large language models (LLMs) with a procedural 3D scene generator. Specifically, Scene Copilot consists of Scene Codex, BlenderGPT, and Human in the loop. Scene Codex is designed to translate textual user input into commands understandable by the 3D scene generator. BlenderGPT provides users with an intuitive and direct way to precisely control the generated 3D scene and the final output video. Furthermore, users can utilize Blender UI to receive instant visual feedback. Additionally, we have curated a procedural dataset of objects in code format to further enhance our system's capabilities. Each component works seamlessly together to support users in generating desired 3D scenes. Extensive experiments demonstrate the capability of our framework in customizing 3D scenes and video generation.
			</p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">The Pipeline</h2>
        <div class="publication-video">
          <img src="./static/images/figure_pipeline_chart.jpg"></img>
        </div>
	<div class="content has-text-justified">
		<p>
			Overview of the Scene Copilot with procedural dataset. Starting with a user textual input, Scene Codex combines an LLM with an RAG database of the Infinigen code and generates an Infinigen executable Python command. Infinigen initially creates a coarse scene, which is converted into textual format so that LLMs can comprehend objects and metadata in the scene. Such scene file is condensed into a coarse RAG database. BlenderGPT, incorporating Blender and LLM, utilizes this database to edit and modify the 3D contents in the scene with user involved through either textual or visual interaction. The updated coarse scene is fed back to Infinigen to create a fine scene. Similar to coarse scene, it is condensed into a fine RAG database, and BlenderGPT collaborates both databases while editing the final scene. Meanwhile, The procedural dataset will provide the requested procedural asset code. The finished scene is then rendered by Inifnigen and outputs the requested video.
		</p> <br><br>
    </div>
      </div>
    </div>
  </div>
  
      <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">The Demo of Scene Co-piolt</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/ejkSBjt8oSk?si=_0Xwz_w9E0T-8NPH"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
			<div class="content has-text-justified">
		<p>
			<br>Blender is designed for 3D editing, and it is intuitive and efficient to interact with 3D scenes through the GUI. Therefore, to allow users to control the objects in the scene precisely, we believe it is essential to preserve the user interface. With both visual and textual interactions available, users can select an object and then prompt BlenderGPT with a textual request. The video demonstrates an example of asking the camera to follow a snake’s movement in the scene. Three snakes are shown as white cubic placeholders in this coarse scene. As there are multiple snakes in the scene, it could be challenging and inefficient to use only textual input to describe the desired object. Instead, the user can directly click on the snake object with the textual input “follow the selected object during the whole animation”.
		</p>
    </div>
      </div>
    </div>
    <!--/ Paper video. -->
		<br>
	    <center> <h2 class="title is-3">Comparison of Infinigen and Scene Co-pilot</h2> </center></br>
		<div>
		<div class="columns is-vcentered interpolation-panel ">
          <div class="column is-6 has-text-centered">
	    <video class="item" poster="" id="chair-tp" autoplay controls muted loop playsinline width="100%" height="100%">
            <source src="./static/videos/Fig11a_before_edit_graveyard at sunset.mp4"
                    type="video/mp4">		
        </video>
            <p class="caption"><b>Infinigen</b>: Graveyard at sunset</p>
          </div>
		  
		<div class="column is-6 has-text-centered">
	    <video class="item" poster="" id="chair-tp" autoplay controls muted loop playsinline width="100%" height="100%">
            <source src="./static/videos/Fig11a_after_edit_graveyard at sunset.mp4"
                    type="video/mp4">		
        </video>
            <p class="caption"><b>Scene Copilot</b>: Graveyard at sunset</p>
        </div>
		</div>
		
				<div class="columns is-vcentered interpolation-panel">
          <div class="column is-6 has-text-centered">
	    <video class="item" poster="" id="chair-tp" autoplay controls muted loop playsinline width="100%" height="100%">
            <source src="./static/videos/Fig11b_before_edit_a relaxing scenery of beach view under cloudy sky.mp4"
                    type="video/mp4">		
        </video>
            <p class="caption"><b>Infinigen</b>: Relaxing scenery of beach view under cloudy sky</p>
          </div>
		  
		<div class="column is-6 has-text-centered">
	    <video class="item" poster="" id="chair-tp" autoplay controls muted loop playsinline width="100%" height="100%">
            <source src="./static/videos/Fig11b_after_edit_a relaxing scenery of beach view under cloudy sky.mp4"
                    type="video/mp4">		
        </video>
            <p class="caption"><b>Scene Copilot</b>: Relaxing scenery of beach view under cloudy sky</p>
        </div>
		</div>
		
		<div class="columns is-vcentered interpolation-panel">
          <div class="column is-6 has-text-centered">
	    <video class="item" poster="" id="chair-tp" autoplay controls muted loop playsinline width="100%" height="100%">
            <source src="./static/videos/Fig11c_before_edit_time lapse of a sunset sky in the countryside.mp4"
                    type="video/mp4">		
        </video>
            <p class="caption"><b>Infinigen</b>: Time lapse of a sunset sky in the countryside</p>
          </div>
		  
		<div class="column is-6 has-text-centered">
	    <video class="item" poster="" id="chair-tp" autoplay controls muted loop playsinline width="100%" height="100%">
            <source src="./static/videos/Fig11c_after_edited_time lapse of a sunset sky in the countryside.mp4"
                    type="video/mp4">		
        </video>
            <p class="caption"><b>Scene Copilot</b>: Time lapse of a sunset sky in the countryside</p>
        </div>
		

		</div>
		</div>
		<br>
	<div class="columns is-vcentered interpolation-panel has-text-justified" style="background-color:#F5F5F5;" >
		<p style="margin:5px">
			  We compare the rendered videos between the direct output videos from Infinigen and the results after editing with Scene Copilot. Note that we optimized Scene Codex specifically for two different tasks. Because of Infinigen’s randomness, the direct output videos have a high probability of not focusing on the main subjects or may even fail to generate the requested assets. In contrast, with Scene Copilot, the user, acting as a “director”, can have more control over the scene and the output video. For example, in the graveyard video, since Infinigen does not include a “graveyard” in the asset, the camera is pointed in a random direction. However, using BlenderGPT, we generated a church and gravestones with fixed camera animation.<br><br>
			</p>
		
        </div>

	</div>

</section>

<section class="hero is-light is-small">
<br>
<center> <h2 class="title is-3">Long Videos Generated by Scene Copilot</h2> </center></br>
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="video-margin">
	 
	    <center><iframe class="item" src="https://www.youtube.com/embed/5AXHoHmR_Vc?si=K5ZpUyb0SEtYBjEL"
                  frameborder="0" allow="autoplay; encrypted-media"></iframe>
			<div class="caption">
			 A 30-second shot from Arctic
			</div>
		</center>
		</div>

        <div class="video-margin">
	 
	    <center><iframe class="item" src="https://www.youtube.com/embed/Ya_cwdevmes?si=-EIvoWf8xe40ujre"
                  frameborder="0" allow="autoplay; encrypted-media"></iframe>
			<div class="caption">
			 A 30-second video of the desert
			</div>
		</center>
		</div>
		
		
		        <div class="video-margin">
	 
	    <center><iframe class="item" src="https://www.youtube.com/embed/fE_XTye77Sk?si=l_Wq2OW7Uzq5PMLJ"
                  frameborder="0" allow="autoplay; encrypted-media"></iframe>
			<div class="caption">
			 A 30-second video of the coast
			</div>
		</center>
		</div>
		
		        <div class="video-margin">
	 
	    <center><iframe class="item" src="https://www.youtube.com/embed/omv_YD4EPTw?si=nie5j65ZBJv8mFsI"
                  frameborder="0" allow="autoplay; encrypted-media"></iframe>
			<div class="caption">
			 A 30-second shot of the canyon
			</div>
		</center>
		</div>
		
		        <div class="video-margin">
	 
	    <center><iframe class="item" src="https://www.youtube.com/embed/v33W3uANmmQ?si=qo7nk7ugG_sjt9AS"
                  frameborder="0" allow="autoplay; encrypted-media"></iframe>
			<div class="caption">
			 A 1-minute video of Arctic
			</div>
		</center>
		</div>
		
		        <div class="video-margin">
	 
	    <center><iframe class="item" src="https://www.youtube.com/embed/FLg9HZvEqkg?si=Yk2oSoxt8-tQolNc"
                  frameborder="0" allow="autoplay; encrypted-media"></iframe>
			<div class="caption">
			 A 1-minute video of desert
			</div>
		</center>
		</div>
		
		        <div class="video-margin">
	 
	    <center><iframe class="item" src="https://www.youtube.com/embed/Lx0-ciQOcL4?si=l6Yva9fLy1F_fOU2"
                  frameborder="0" allow="autoplay; encrypted-media"></iframe>
			<div class="caption">
			 A 2-minute video of corals
			</div>
		</center>
		</div>
		
		        <div class="video-margin">
	 
	    <center><iframe class="item" src="https://www.youtube.com/embed/YlojwXm7aGw?si=YZUlAYBbCZlolb12"
                  frameborder="0" allow="autoplay; encrypted-media"></iframe>
			<div class="caption">
			 A 2-minute video of underwater
			</div>
		</center>
		</div>
				 <div class="video-margin">
	 
	    <center><iframe class="item" src="https://www.youtube.com/embed/Ur59OQ9VYVc?si=CCkso0q4yFRlGm9F"
                  frameborder="0" allow="autoplay; encrypted-media"></iframe>
			<div class="caption">
			 A 10-minute video of plain
			</div>
		</center>
		</div>
      </div>
		<div class="content has-text-justified">
		<br>
			<p>
			  We further rendered additional video examples to demonstrate our long-video generation capabilities. We created one 10-minute video, two 2-minute videos, three 1-minute videos, and three 30-second videos. We have included these examples to showcase the utility of our procedural dataset and the capabilities of Scene Copilot beyond the creation of generic environments and scenery.
			</p>
        </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{Zhaofang2025scenecopilot,
  author    = {Zhaofang Qian, Abolfazl Sharifi, Tucker Carroll, Ser-Nam Lim},
  title     = {Scene Co-pilot: Procedural Text to Video Generation with Human in the Loop},
  journal   = {CVPR},
  year      = {2025},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://anonymous.4open.science/r/scene_copilot-1EF6/README.md" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

		<center>
          <p>
            This website used this <a
              href="https://github.com/nerfies/nerfies.github.io">repository</a> as a start point.
			  
          </p>
		</center>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
